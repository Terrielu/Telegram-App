from fastapi import FastAPI, Request
from pydantic import BaseModel
import os
from openai import OpenAI
import logging

# –õ–æ–≥–≥–µ—Ä (–ø–æ –∂–µ–ª–∞–Ω–∏—é)
logging.basicConfig(level=logging.INFO)

# –ü–æ–ª—É—á–∞–µ–º API-–∫–ª—é—á
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    logging.warning("‚ùó –ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è OPENAI_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞!")

# –°–æ–∑–¥–∞—ë–º –∫–ª–∏–µ–Ω—Ç–∞
client = OpenAI(api_key=api_key)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è FastAPI
app = FastAPI()

# –°—Ö–µ–º–∞ —Ç–µ–ª–∞ –∑–∞–ø—Ä–æ—Å–∞
class PromptRequest(BaseModel):
    prompt: str

@app.post("/search")
async def search(request: Request, body: PromptRequest):
    user_ip = request.client.host
    user_prompt = body.prompt
    logging.info(f"üì® –ó–∞–ø—Ä–æ—Å –æ—Ç IP {user_ip}: {user_prompt}")

    try:
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ OpenAI
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "–¢—ã –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –ø–æ–º–æ–≥–∞—é—â–∏–π –Ω–∞–π—Ç–∏ –∂–∏–ª—å—ë."},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.7,
        )

        reply = response.choices[0].message.content
        logging.info(f"‚úÖ –û—Ç–≤–µ—Ç –æ—Ç OpenAI: {reply}")
        return {"reply": reply}

    except Exception as e:
        logging.error(f"üî• –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ OpenAI: {e}")
        return {"error": str(e)}
